[0m[[0m[31merror[0m] [0m[0mjava.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2688)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.map(List.scala:293)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Option.getOrElse(Option.scala:189)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:444)[0m
[0m[[0m[31merror[0m] [0m[0m	at Main$.main(Main.scala:42)[0m
[0m[[0m[31merror[0m] [0m[0m	at Main.main(Main.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.reflect.Method.invoke(Method.java:566)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:144)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:94)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:121)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:187)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:121)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1986)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1925)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:367)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:829)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2592)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2686)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.map(List.scala:293)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Option.getOrElse(Option.scala:189)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:444)[0m
[0m[[0m[31merror[0m] [0m[0m	at Main$.main(Main.scala:42)[0m
[0m[[0m[31merror[0m] [0m[0m	at Main.main(Main.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.reflect.Method.invoke(Method.java:566)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:144)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:94)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:121)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:187)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:121)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1986)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1925)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:367)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:829)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
